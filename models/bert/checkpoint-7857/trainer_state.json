{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7857,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006363752068219423,
      "grad_norm": 2.0949907302856445,
      "learning_rate": 1.246819338422392e-06,
      "loss": 0.6854,
      "step": 50
    },
    {
      "epoch": 0.012727504136438845,
      "grad_norm": 3.0142157077789307,
      "learning_rate": 2.5190839694656487e-06,
      "loss": 0.6744,
      "step": 100
    },
    {
      "epoch": 0.019091256204658267,
      "grad_norm": 3.4552245140075684,
      "learning_rate": 3.791348600508906e-06,
      "loss": 0.6287,
      "step": 150
    },
    {
      "epoch": 0.02545500827287769,
      "grad_norm": 2.049457550048828,
      "learning_rate": 5.063613231552163e-06,
      "loss": 0.4184,
      "step": 200
    },
    {
      "epoch": 0.03181876034109711,
      "grad_norm": 0.5185334086418152,
      "learning_rate": 6.335877862595419e-06,
      "loss": 0.1143,
      "step": 250
    },
    {
      "epoch": 0.038182512409316534,
      "grad_norm": 0.21364359557628632,
      "learning_rate": 7.608142493638677e-06,
      "loss": 0.0184,
      "step": 300
    },
    {
      "epoch": 0.04454626447753596,
      "grad_norm": 0.11593141406774521,
      "learning_rate": 8.880407124681935e-06,
      "loss": 0.0347,
      "step": 350
    },
    {
      "epoch": 0.05091001654575538,
      "grad_norm": 0.07444249838590622,
      "learning_rate": 1.0152671755725192e-05,
      "loss": 0.0054,
      "step": 400
    },
    {
      "epoch": 0.0572737686139748,
      "grad_norm": 0.05594212934374809,
      "learning_rate": 1.1424936386768449e-05,
      "loss": 0.0271,
      "step": 450
    },
    {
      "epoch": 0.06363752068219422,
      "grad_norm": 0.03586050122976303,
      "learning_rate": 1.2697201017811707e-05,
      "loss": 0.0026,
      "step": 500
    },
    {
      "epoch": 0.07000127275041364,
      "grad_norm": 0.025606794282794,
      "learning_rate": 1.3969465648854963e-05,
      "loss": 0.0019,
      "step": 550
    },
    {
      "epoch": 0.07636502481863307,
      "grad_norm": 0.023613523691892624,
      "learning_rate": 1.524173027989822e-05,
      "loss": 0.0014,
      "step": 600
    },
    {
      "epoch": 0.08272877688685248,
      "grad_norm": 0.032937854528427124,
      "learning_rate": 1.6513994910941476e-05,
      "loss": 0.0025,
      "step": 650
    },
    {
      "epoch": 0.08909252895507191,
      "grad_norm": 0.012532969936728477,
      "learning_rate": 1.7786259541984735e-05,
      "loss": 0.0009,
      "step": 700
    },
    {
      "epoch": 0.09545628102329133,
      "grad_norm": 0.013596732169389725,
      "learning_rate": 1.9058524173027994e-05,
      "loss": 0.06,
      "step": 750
    },
    {
      "epoch": 0.10182003309151076,
      "grad_norm": 0.00969501119107008,
      "learning_rate": 1.996323009475322e-05,
      "loss": 0.0007,
      "step": 800
    },
    {
      "epoch": 0.10818378515973018,
      "grad_norm": 0.0074572390876710415,
      "learning_rate": 1.9821807382265593e-05,
      "loss": 0.0005,
      "step": 850
    },
    {
      "epoch": 0.1145475372279496,
      "grad_norm": 0.008128220215439796,
      "learning_rate": 1.968038466977797e-05,
      "loss": 0.0352,
      "step": 900
    },
    {
      "epoch": 0.12091128929616902,
      "grad_norm": 0.00659816013649106,
      "learning_rate": 1.9538961957290342e-05,
      "loss": 0.0005,
      "step": 950
    },
    {
      "epoch": 0.12727504136438844,
      "grad_norm": 0.006826582830399275,
      "learning_rate": 1.9397539244802715e-05,
      "loss": 0.0003,
      "step": 1000
    },
    {
      "epoch": 0.13363879343260787,
      "grad_norm": 0.006623400840908289,
      "learning_rate": 1.925611653231509e-05,
      "loss": 0.0003,
      "step": 1050
    },
    {
      "epoch": 0.14000254550082727,
      "grad_norm": 0.004302437882870436,
      "learning_rate": 1.9114693819827465e-05,
      "loss": 0.0006,
      "step": 1100
    },
    {
      "epoch": 0.1463662975690467,
      "grad_norm": 0.0038208940532058477,
      "learning_rate": 1.897327110733984e-05,
      "loss": 0.0002,
      "step": 1150
    },
    {
      "epoch": 0.15273004963726614,
      "grad_norm": 0.0037883021868765354,
      "learning_rate": 1.8831848394852214e-05,
      "loss": 0.0002,
      "step": 1200
    },
    {
      "epoch": 0.15909380170548557,
      "grad_norm": 0.00475008599460125,
      "learning_rate": 1.869042568236459e-05,
      "loss": 0.0079,
      "step": 1250
    },
    {
      "epoch": 0.16545755377370497,
      "grad_norm": 0.0034438646398484707,
      "learning_rate": 1.8549002969876964e-05,
      "loss": 0.0001,
      "step": 1300
    },
    {
      "epoch": 0.1718213058419244,
      "grad_norm": 142.7711944580078,
      "learning_rate": 1.840758025738934e-05,
      "loss": 0.0522,
      "step": 1350
    },
    {
      "epoch": 0.17818505791014383,
      "grad_norm": 0.0044286795891821384,
      "learning_rate": 1.8266157544901713e-05,
      "loss": 0.0401,
      "step": 1400
    },
    {
      "epoch": 0.18454880997836323,
      "grad_norm": 0.005821720696985722,
      "learning_rate": 1.812473483241409e-05,
      "loss": 0.0004,
      "step": 1450
    },
    {
      "epoch": 0.19091256204658266,
      "grad_norm": 146.5928192138672,
      "learning_rate": 1.7983312119926462e-05,
      "loss": 0.0163,
      "step": 1500
    },
    {
      "epoch": 0.1972763141148021,
      "grad_norm": 0.002835026476532221,
      "learning_rate": 1.7841889407438836e-05,
      "loss": 0.0158,
      "step": 1550
    },
    {
      "epoch": 0.20364006618302152,
      "grad_norm": 15.144662857055664,
      "learning_rate": 1.7700466694951212e-05,
      "loss": 0.0398,
      "step": 1600
    },
    {
      "epoch": 0.21000381825124093,
      "grad_norm": 0.004827984608709812,
      "learning_rate": 1.7559043982463585e-05,
      "loss": 0.0003,
      "step": 1650
    },
    {
      "epoch": 0.21636757031946036,
      "grad_norm": 0.002405347302556038,
      "learning_rate": 1.7417621269975958e-05,
      "loss": 0.0002,
      "step": 1700
    },
    {
      "epoch": 0.2227313223876798,
      "grad_norm": 0.003146063070744276,
      "learning_rate": 1.7276198557488334e-05,
      "loss": 0.0002,
      "step": 1750
    },
    {
      "epoch": 0.2290950744558992,
      "grad_norm": 0.002220720052719116,
      "learning_rate": 1.7134775845000707e-05,
      "loss": 0.0001,
      "step": 1800
    },
    {
      "epoch": 0.23545882652411862,
      "grad_norm": 0.0038381076883524656,
      "learning_rate": 1.6993353132513084e-05,
      "loss": 0.0182,
      "step": 1850
    },
    {
      "epoch": 0.24182257859233805,
      "grad_norm": 0.0016413585981354117,
      "learning_rate": 1.6851930420025457e-05,
      "loss": 0.0407,
      "step": 1900
    },
    {
      "epoch": 0.24818633066055745,
      "grad_norm": 0.003584544640034437,
      "learning_rate": 1.6710507707537833e-05,
      "loss": 0.0033,
      "step": 1950
    },
    {
      "epoch": 0.2545500827287769,
      "grad_norm": 0.00293215224519372,
      "learning_rate": 1.6569084995050206e-05,
      "loss": 0.0347,
      "step": 2000
    },
    {
      "epoch": 0.2609138347969963,
      "grad_norm": 0.004191358108073473,
      "learning_rate": 1.6427662282562583e-05,
      "loss": 0.0101,
      "step": 2050
    },
    {
      "epoch": 0.26727758686521574,
      "grad_norm": 0.0023565541487187147,
      "learning_rate": 1.6286239570074956e-05,
      "loss": 0.0074,
      "step": 2100
    },
    {
      "epoch": 0.2736413389334352,
      "grad_norm": 0.001757915480993688,
      "learning_rate": 1.614481685758733e-05,
      "loss": 0.0001,
      "step": 2150
    },
    {
      "epoch": 0.28000509100165455,
      "grad_norm": 0.0020013884641230106,
      "learning_rate": 1.6003394145099705e-05,
      "loss": 0.0001,
      "step": 2200
    },
    {
      "epoch": 0.286368843069874,
      "grad_norm": 0.001522124046459794,
      "learning_rate": 1.586197143261208e-05,
      "loss": 0.0001,
      "step": 2250
    },
    {
      "epoch": 0.2927325951380934,
      "grad_norm": 0.0015214125160127878,
      "learning_rate": 1.5720548720124455e-05,
      "loss": 0.0001,
      "step": 2300
    },
    {
      "epoch": 0.29909634720631284,
      "grad_norm": 0.0026107083540409803,
      "learning_rate": 1.5579126007636828e-05,
      "loss": 0.0001,
      "step": 2350
    },
    {
      "epoch": 0.30546009927453227,
      "grad_norm": 0.0048018754459917545,
      "learning_rate": 1.54377032951492e-05,
      "loss": 0.0375,
      "step": 2400
    },
    {
      "epoch": 0.3118238513427517,
      "grad_norm": 0.001855724141933024,
      "learning_rate": 1.5296280582661577e-05,
      "loss": 0.0001,
      "step": 2450
    },
    {
      "epoch": 0.31818760341097113,
      "grad_norm": 0.003940458409488201,
      "learning_rate": 1.5154857870173952e-05,
      "loss": 0.0101,
      "step": 2500
    },
    {
      "epoch": 0.3245513554791905,
      "grad_norm": 0.002401077887043357,
      "learning_rate": 1.5013435157686325e-05,
      "loss": 0.0002,
      "step": 2550
    },
    {
      "epoch": 0.33091510754740994,
      "grad_norm": 0.0006561913178302348,
      "learning_rate": 1.48720124451987e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 0.33727885961562937,
      "grad_norm": 0.001080650370568037,
      "learning_rate": 1.4730589732711073e-05,
      "loss": 0.0146,
      "step": 2650
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 0.0008193418034352362,
      "learning_rate": 1.458916702022345e-05,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 0.35000636375206823,
      "grad_norm": 0.001680205576121807,
      "learning_rate": 1.4447744307735822e-05,
      "loss": 0.0417,
      "step": 2750
    },
    {
      "epoch": 0.35637011582028766,
      "grad_norm": 0.0009167076204903424,
      "learning_rate": 1.4306321595248199e-05,
      "loss": 0.0021,
      "step": 2800
    },
    {
      "epoch": 0.3627338678885071,
      "grad_norm": 0.0005978298140689731,
      "learning_rate": 1.4164898882760572e-05,
      "loss": 0.003,
      "step": 2850
    },
    {
      "epoch": 0.36909761995672646,
      "grad_norm": 0.0010036048479378223,
      "learning_rate": 1.4023476170272946e-05,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 0.3754613720249459,
      "grad_norm": 0.0010171105386689305,
      "learning_rate": 1.3882053457785321e-05,
      "loss": 0.0,
      "step": 2950
    },
    {
      "epoch": 0.3818251240931653,
      "grad_norm": 0.0008611393277533352,
      "learning_rate": 1.3740630745297696e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.38818887616138475,
      "grad_norm": 0.000999887241050601,
      "learning_rate": 1.3599208032810069e-05,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 0.3945526282296042,
      "grad_norm": 0.0005843664985150099,
      "learning_rate": 1.3457785320322445e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.4009163802978236,
      "grad_norm": 0.000926479697227478,
      "learning_rate": 1.3316362607834818e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 0.40728013236604305,
      "grad_norm": 0.041306838393211365,
      "learning_rate": 1.3174939895347195e-05,
      "loss": 0.0918,
      "step": 3200
    },
    {
      "epoch": 0.4136438844342624,
      "grad_norm": 0.0027493846137076616,
      "learning_rate": 1.3033517182859568e-05,
      "loss": 0.0003,
      "step": 3250
    },
    {
      "epoch": 0.42000763650248185,
      "grad_norm": 0.002390677109360695,
      "learning_rate": 1.2892094470371943e-05,
      "loss": 0.0001,
      "step": 3300
    },
    {
      "epoch": 0.4263713885707013,
      "grad_norm": 0.0020457461941987276,
      "learning_rate": 1.2750671757884316e-05,
      "loss": 0.0001,
      "step": 3350
    },
    {
      "epoch": 0.4327351406389207,
      "grad_norm": 17.661828994750977,
      "learning_rate": 1.2609249045396692e-05,
      "loss": 0.0006,
      "step": 3400
    },
    {
      "epoch": 0.43909889270714014,
      "grad_norm": 0.0008341697393916547,
      "learning_rate": 1.2467826332909065e-05,
      "loss": 0.0018,
      "step": 3450
    },
    {
      "epoch": 0.4454626447753596,
      "grad_norm": 0.0027905735187232494,
      "learning_rate": 1.2326403620421442e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 0.45182639684357895,
      "grad_norm": 0.001267298124730587,
      "learning_rate": 1.2184980907933815e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 0.4581901489117984,
      "grad_norm": 0.0038632159121334553,
      "learning_rate": 1.204355819544619e-05,
      "loss": 0.0389,
      "step": 3600
    },
    {
      "epoch": 0.4645539009800178,
      "grad_norm": 0.0019237757660448551,
      "learning_rate": 1.1902135482958564e-05,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 0.47091765304823724,
      "grad_norm": 0.0008785861427895725,
      "learning_rate": 1.1760712770470939e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 0.47728140511645667,
      "grad_norm": 0.001718031126074493,
      "learning_rate": 1.1619290057983312e-05,
      "loss": 0.0001,
      "step": 3750
    },
    {
      "epoch": 0.4836451571846761,
      "grad_norm": 0.0010457078460603952,
      "learning_rate": 1.1477867345495688e-05,
      "loss": 0.0323,
      "step": 3800
    },
    {
      "epoch": 0.49000890925289553,
      "grad_norm": 0.0005284507060423493,
      "learning_rate": 1.1336444633008061e-05,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 0.4963726613211149,
      "grad_norm": 0.0012165723601356149,
      "learning_rate": 1.1195021920520438e-05,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 0.5027364133893344,
      "grad_norm": 0.0004295832186471671,
      "learning_rate": 1.105359920803281e-05,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 0.5091001654575538,
      "grad_norm": 0.0008235747809521854,
      "learning_rate": 1.0912176495545185e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 0.0012143489439040422,
      "learning_rate": 1.0770753783057558e-05,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 0.5218276695939926,
      "grad_norm": 0.004042632412165403,
      "learning_rate": 1.0629331070569935e-05,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 0.528191421662212,
      "grad_norm": 0.00041856462485156953,
      "learning_rate": 1.0487908358082308e-05,
      "loss": 0.0,
      "step": 4150
    },
    {
      "epoch": 0.5345551737304315,
      "grad_norm": 0.0005280273035168648,
      "learning_rate": 1.0346485645594684e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 0.5409189257986509,
      "grad_norm": 0.00038167083403095603,
      "learning_rate": 1.0205062933107057e-05,
      "loss": 0.0,
      "step": 4250
    },
    {
      "epoch": 0.5472826778668703,
      "grad_norm": 0.0004927864065393806,
      "learning_rate": 1.0063640220619432e-05,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 0.5536464299350897,
      "grad_norm": 0.0004298464336898178,
      "learning_rate": 9.922217508131807e-06,
      "loss": 0.0,
      "step": 4350
    },
    {
      "epoch": 0.5600101820033091,
      "grad_norm": 0.0006198323098942637,
      "learning_rate": 9.780794795644182e-06,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 0.5663739340715286,
      "grad_norm": 0.0006061624735593796,
      "learning_rate": 9.639372083156556e-06,
      "loss": 0.0,
      "step": 4450
    },
    {
      "epoch": 0.572737686139748,
      "grad_norm": 0.0023608694318681955,
      "learning_rate": 9.497949370668931e-06,
      "loss": 0.0641,
      "step": 4500
    },
    {
      "epoch": 0.5791014382079674,
      "grad_norm": 0.0006911683594807982,
      "learning_rate": 9.356526658181306e-06,
      "loss": 0.0001,
      "step": 4550
    },
    {
      "epoch": 0.5854651902761868,
      "grad_norm": 0.001537826843559742,
      "learning_rate": 9.215103945693679e-06,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 0.5918289423444063,
      "grad_norm": 0.0012556868605315685,
      "learning_rate": 9.073681233206054e-06,
      "loss": 0.0,
      "step": 4650
    },
    {
      "epoch": 0.5981926944126257,
      "grad_norm": 0.0010975198820233345,
      "learning_rate": 8.932258520718428e-06,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 0.6045564464808451,
      "grad_norm": 0.0007016090676188469,
      "learning_rate": 8.790835808230801e-06,
      "loss": 0.0028,
      "step": 4750
    },
    {
      "epoch": 0.6109201985490645,
      "grad_norm": 0.00032074033515527844,
      "learning_rate": 8.649413095743176e-06,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 0.001042297575622797,
      "learning_rate": 8.50799038325555e-06,
      "loss": 0.0378,
      "step": 4850
    },
    {
      "epoch": 0.6236477026855034,
      "grad_norm": 0.0003974071878474206,
      "learning_rate": 8.366567670767925e-06,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 0.6300114547537228,
      "grad_norm": 0.001802794518880546,
      "learning_rate": 8.2251449582803e-06,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 0.6363752068219423,
      "grad_norm": 0.000635018921457231,
      "learning_rate": 8.083722245792675e-06,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 0.6427389588901616,
      "grad_norm": 0.003162955865263939,
      "learning_rate": 7.94229953330505e-06,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 0.649102710958381,
      "grad_norm": 0.00043172494042664766,
      "learning_rate": 7.800876820817423e-06,
      "loss": 0.0002,
      "step": 5100
    },
    {
      "epoch": 0.6554664630266005,
      "grad_norm": 0.0006314125494100153,
      "learning_rate": 7.659454108329797e-06,
      "loss": 0.0002,
      "step": 5150
    },
    {
      "epoch": 0.6618302150948199,
      "grad_norm": 0.0007295287796296179,
      "learning_rate": 7.518031395842172e-06,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.6681939671630394,
      "grad_norm": 0.0008823077660053968,
      "learning_rate": 7.376608683354547e-06,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 0.6745577192312587,
      "grad_norm": 0.00018663010268937796,
      "learning_rate": 7.235185970866922e-06,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 0.6809214712994782,
      "grad_norm": 0.0010950263822451234,
      "learning_rate": 7.0937632583792955e-06,
      "loss": 0.052,
      "step": 5350
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 0.0013238399988040328,
      "learning_rate": 6.95234054589167e-06,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 0.693648975435917,
      "grad_norm": 0.0017642243765294552,
      "learning_rate": 6.810917833404045e-06,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 0.7000127275041365,
      "grad_norm": 0.0007948841666802764,
      "learning_rate": 6.66949512091642e-06,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 0.7063764795723558,
      "grad_norm": 0.00042135067633353174,
      "learning_rate": 6.528072408428794e-06,
      "loss": 0.0,
      "step": 5550
    },
    {
      "epoch": 0.7127402316405753,
      "grad_norm": 0.0010365425841882825,
      "learning_rate": 6.386649695941168e-06,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 0.7191039837087947,
      "grad_norm": 0.000782727962359786,
      "learning_rate": 6.245226983453543e-06,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 0.7254677357770142,
      "grad_norm": 0.0007633614586666226,
      "learning_rate": 6.103804270965917e-06,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 0.7318314878452336,
      "grad_norm": 0.0004216453817207366,
      "learning_rate": 5.962381558478292e-06,
      "loss": 0.0001,
      "step": 5750
    },
    {
      "epoch": 0.7381952399134529,
      "grad_norm": 0.0002669034292921424,
      "learning_rate": 5.820958845990666e-06,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 0.7445589919816724,
      "grad_norm": 0.003040359588339925,
      "learning_rate": 5.679536133503041e-06,
      "loss": 0.0,
      "step": 5850
    },
    {
      "epoch": 0.7509227440498918,
      "grad_norm": 0.0005212830728851259,
      "learning_rate": 5.538113421015415e-06,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 0.7572864961181113,
      "grad_norm": 0.0008260685135610402,
      "learning_rate": 5.39669070852779e-06,
      "loss": 0.0004,
      "step": 5950
    },
    {
      "epoch": 0.7636502481863306,
      "grad_norm": 0.002020694315433502,
      "learning_rate": 5.2552679960401645e-06,
      "loss": 0.047,
      "step": 6000
    },
    {
      "epoch": 0.7700140002545501,
      "grad_norm": 0.0021887049078941345,
      "learning_rate": 5.113845283552538e-06,
      "loss": 0.0353,
      "step": 6050
    },
    {
      "epoch": 0.7763777523227695,
      "grad_norm": 0.00265706074424088,
      "learning_rate": 4.972422571064913e-06,
      "loss": 0.0001,
      "step": 6100
    },
    {
      "epoch": 0.7827415043909889,
      "grad_norm": 0.005092632491141558,
      "learning_rate": 4.830999858577288e-06,
      "loss": 0.0932,
      "step": 6150
    },
    {
      "epoch": 0.7891052564592084,
      "grad_norm": 0.0008260530885308981,
      "learning_rate": 4.6895771460896625e-06,
      "loss": 0.0002,
      "step": 6200
    },
    {
      "epoch": 0.7954690085274277,
      "grad_norm": 0.0020068963058292866,
      "learning_rate": 4.548154433602036e-06,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 0.8018327605956472,
      "grad_norm": 0.00023442042584065348,
      "learning_rate": 4.406731721114411e-06,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 0.8081965126638666,
      "grad_norm": 0.00126973120495677,
      "learning_rate": 4.265309008626786e-06,
      "loss": 0.0,
      "step": 6350
    },
    {
      "epoch": 0.8145602647320861,
      "grad_norm": 0.0002841681125573814,
      "learning_rate": 4.12388629613916e-06,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 0.8209240168003055,
      "grad_norm": 0.0011406403500586748,
      "learning_rate": 3.9824635836515345e-06,
      "loss": 0.0,
      "step": 6450
    },
    {
      "epoch": 0.8272877688685248,
      "grad_norm": 0.0003063967451453209,
      "learning_rate": 3.841040871163909e-06,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 0.8336515209367443,
      "grad_norm": 0.0009184069931507111,
      "learning_rate": 3.6996181586762835e-06,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 0.8400152730049637,
      "grad_norm": 0.0007298992131836712,
      "learning_rate": 3.5581954461886582e-06,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 0.8463790250731832,
      "grad_norm": 0.0015680224169045687,
      "learning_rate": 3.4167727337010326e-06,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 0.8527427771414026,
      "grad_norm": 0.001006657024845481,
      "learning_rate": 3.275350021213407e-06,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 0.8591065292096219,
      "grad_norm": 0.003792860545217991,
      "learning_rate": 3.1339273087257816e-06,
      "loss": 0.0408,
      "step": 6750
    },
    {
      "epoch": 0.8654702812778414,
      "grad_norm": 0.00023123489518184215,
      "learning_rate": 2.992504596238156e-06,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 0.8718340333460608,
      "grad_norm": 0.0012954273261129856,
      "learning_rate": 2.8510818837505306e-06,
      "loss": 0.0001,
      "step": 6850
    },
    {
      "epoch": 0.8781977854142803,
      "grad_norm": 0.0008883263217285275,
      "learning_rate": 2.709659171262905e-06,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 0.8845615374824997,
      "grad_norm": 0.00043428444769233465,
      "learning_rate": 2.5682364587752797e-06,
      "loss": 0.0,
      "step": 6950
    },
    {
      "epoch": 0.8909252895507191,
      "grad_norm": 0.006238547153770924,
      "learning_rate": 2.426813746287654e-06,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 0.8972890416189385,
      "grad_norm": 0.0004317931889090687,
      "learning_rate": 2.2853910338000283e-06,
      "loss": 0.0,
      "step": 7050
    },
    {
      "epoch": 0.9036527936871579,
      "grad_norm": 0.0014735752483829856,
      "learning_rate": 2.143968321312403e-06,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.9100165457553774,
      "grad_norm": 0.0006850995705462992,
      "learning_rate": 2.0025456088247773e-06,
      "loss": 0.0412,
      "step": 7150
    },
    {
      "epoch": 0.9163802978235968,
      "grad_norm": 0.00039040306000970304,
      "learning_rate": 1.8611228963371518e-06,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 0.9227440498918162,
      "grad_norm": 0.0003874718677252531,
      "learning_rate": 1.7197001838495263e-06,
      "loss": 0.0,
      "step": 7250
    },
    {
      "epoch": 0.9291078019600356,
      "grad_norm": 0.0007716871914453804,
      "learning_rate": 1.5782774713619009e-06,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 0.9354715540282551,
      "grad_norm": 0.0014460592065006495,
      "learning_rate": 1.4368547588742754e-06,
      "loss": 0.0,
      "step": 7350
    },
    {
      "epoch": 0.9418353060964745,
      "grad_norm": 0.0004964314866811037,
      "learning_rate": 1.29543204638665e-06,
      "loss": 0.0001,
      "step": 7400
    },
    {
      "epoch": 0.9481990581646939,
      "grad_norm": 0.0003696925414260477,
      "learning_rate": 1.1540093338990242e-06,
      "loss": 0.0324,
      "step": 7450
    },
    {
      "epoch": 0.9545628102329133,
      "grad_norm": 0.000334759010002017,
      "learning_rate": 1.0125866214113987e-06,
      "loss": 0.0026,
      "step": 7500
    },
    {
      "epoch": 0.9609265623011327,
      "grad_norm": 0.0006553629646077752,
      "learning_rate": 8.711639089237732e-07,
      "loss": 0.0,
      "step": 7550
    },
    {
      "epoch": 0.9672903143693522,
      "grad_norm": 0.0020083384588360786,
      "learning_rate": 7.297411964361477e-07,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 0.9736540664375716,
      "grad_norm": 0.004648760426789522,
      "learning_rate": 5.883184839485222e-07,
      "loss": 0.0,
      "step": 7650
    },
    {
      "epoch": 0.9800178185057911,
      "grad_norm": 0.00023325647634919733,
      "learning_rate": 4.4689577146089664e-07,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 0.9863815705740104,
      "grad_norm": 0.0013857739977538586,
      "learning_rate": 3.0547305897327116e-07,
      "loss": 0.0,
      "step": 7750
    },
    {
      "epoch": 0.9927453226422298,
      "grad_norm": 0.00016412627883255482,
      "learning_rate": 1.640503464856456e-07,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 0.9991090747104493,
      "grad_norm": 0.0024145017378032207,
      "learning_rate": 2.2627633998020082e-08,
      "loss": 0.0,
      "step": 7850
    }
  ],
  "logging_steps": 50,
  "max_steps": 7857,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 520398175620096.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
